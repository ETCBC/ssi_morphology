{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie van morphological_analysis_workshop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaKh2cO7pyqL"
      },
      "source": [
        "import os, collections\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6eMCeWlqZb1",
        "outputId": "7fbe5864-263c-4371-fee6-5093dd9a9f9e"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/your_project_folder/' "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyopyWzHMJRG"
      },
      "source": [
        "def read_data_from_file(filename, data_dict):\n",
        "\n",
        "    with open(filename) as fp:\n",
        "        line = fp.readline()\n",
        "        while line:\n",
        "            bo, ch, ve, text = tuple(line.strip().split('\\t'))\n",
        "            words = text.split()\n",
        "            for w in words:  \n",
        "                # in the output data, composite placenames have a '_', which cannot be found in the input data\n",
        "                words_split = w.split('_')               \n",
        "                for word_split in words_split:\n",
        "                    data_dict[bo].append(word_split)\n",
        "        \n",
        "            line = fp.readline()\n",
        "            \n",
        "    return data_dict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrQKfBKjMJRH"
      },
      "source": [
        "input_file = '/content/ssi_morphology/data/t-in_voc'\n",
        "input_data = collections.defaultdict(list)\n",
        "\n",
        "output_file = '/content/ssi_morphology/data/t-out'\n",
        "output_data = collections.defaultdict(list)\n",
        "\n",
        "input_data = read_data_from_file(input_file, input_data)\n",
        "output_data = read_data_from_file(output_file, output_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9j5WDmePaw",
        "outputId": "be4e419f-ea03-4899-96a1-cdcdb6ffb350"
      },
      "source": [
        "print(len(input_data['Gen']))\n",
        "print(len(output_data['Gen']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20611\n",
            "20611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmq4ubmfMJRH",
        "outputId": "47b85903-4dc1-43ec-8421-b4ce9b9e62eb"
      },
      "source": [
        "input_data['Gen'][0:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B.:R;>CIJT',\n",
              " 'B.@R@>',\n",
              " '>:ELOHIJM',\n",
              " '>;T',\n",
              " 'HAC.@MAJIM',\n",
              " 'W:>;T',\n",
              " 'H@>@REY',\n",
              " 'W:H@>@REY',\n",
              " 'H@J:T@H',\n",
              " 'TOHW.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNedXVOlMJRI",
        "outputId": "b054087a-92ff-4d5a-f3cb-2475a6cb8203"
      },
      "source": [
        "output_data['Gen'][0:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-R>CJT/',\n",
              " 'BR>[',\n",
              " '>LH(J(M/JM',\n",
              " '>T',\n",
              " 'H-CMJ(M/(JM',\n",
              " 'W->T',\n",
              " 'H->RY/:a',\n",
              " 'W-H->RY/:a',\n",
              " 'HJ(H[&TH',\n",
              " 'THW/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7c1KmcIMJRI"
      },
      "source": [
        "def make_in_out_sequences(data_dict, sequence_length):\n",
        "    \n",
        "    all_sequences = []\n",
        "    for words_list in data_dict.values():\n",
        "\n",
        "        for w in range(len(words_list) - sequence_length + 1):\n",
        "    \n",
        "            seq = ' '.join([words_list[ind] for ind in list(range(w, w + sequence_length))])\n",
        "        \n",
        "            # remove some special signs from output data (':', and '='). These only make the sequences longer.\n",
        "            seq = seq.replace(\"=\", \"\").replace(\":a\", \"a\").replace(\":c\", \"c\").replace(\":d\", \"d\").replace(\":du\", \"du\")\n",
        "            all_sequences.append(seq)\n",
        "        \n",
        "    return all_sequences"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2BUTP84XjF1"
      },
      "source": [
        "sequence_length = 1\n",
        "\n",
        "all_in_seqs = make_in_out_sequences(input_data, sequence_length)\n",
        "all_out_seqs = make_in_out_sequences(output_data, sequence_length)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38gyv323MJRJ",
        "outputId": "e7dfee7e-d2f5-4122-846e-9785932da483"
      },
      "source": [
        "all_in_seqs[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B.:R;>CIJT',\n",
              " 'B.@R@>',\n",
              " '>:ELOHIJM',\n",
              " '>;T',\n",
              " 'HAC.@MAJIM',\n",
              " 'W:>;T',\n",
              " 'H@>@REY',\n",
              " 'W:H@>@REY',\n",
              " 'H@J:T@H',\n",
              " 'TOHW.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI4oTf5eX2Sn",
        "outputId": "620fc026-c505-4bde-ae84-1b437bf07f6f"
      },
      "source": [
        "print(len(all_in_seqs))\n",
        "print(len(all_out_seqs))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300676\n",
            "300676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv8HuH9lKJGl",
        "outputId": "e0450c5d-673f-49de-977f-7b4d137b83e2"
      },
      "source": [
        "for i in range(206000,206020):\n",
        "  print(all_in_seqs[i], '---', all_out_seqs[i])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B.:BOW>@M --- B-!!BW>[/+M\n",
            "J@BOW> --- !J!BW>[\n",
            "W.B:Y;>T@M --- W-B-!!(JY>[/T+M\n",
            "J;Y;>W. --- !J!(JY>[W\n",
            "W.BAXAG.IJM --- W-B-(H-XG/JM\n",
            "W.BAM.OW<:ADIJM --- W-B-(H-MW<D/JM\n",
            "T.IH:JEH --- !T!HJH[\n",
            "HAM.IN:X@H --- H-MNX(H/H\n",
            ">;JP@H --- >JP(H/H\n",
            "LAP.@R --- L-(H-PR/a\n",
            "W:>;JP@H --- W->JP(H/H\n",
            "L@>AJIL --- L-(H->JL/a\n",
            "W:LAK.:B@FIJM --- W-L-(H-KBF/JM\n",
            "MAT.AT --- MTT/\n",
            "J@DOW --- JD/+W\n",
            "W:CEMEN --- W-CMN/\n",
            "HIJN --- HJN/\n",
            "L@>;JP@H --- L-(H->JP(H/H\n",
            "W:KIJ --- W-KJ\n",
            "JA<:AFEH --- !J!<FH[\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXhrQPM4pyqV"
      },
      "source": [
        "def prepare_train_data(input_data, output_data):\n",
        "\n",
        "    input_seqs = []\n",
        "    output_seqs = []\n",
        "    input_chars = set()\n",
        "    output_chars = set()\n",
        "\n",
        "    # iterate over all the books\n",
        "    for seq in range(len(input_data)): \n",
        "      \n",
        "        #if len(output_data[seq]) > 40:\n",
        "        #  continue\n",
        "          \n",
        "        if \"*\" in input_data[seq]: # cases of ketiv/qere are complicated, just skip them!\n",
        "          continue\n",
        "\n",
        "        input_list = list(input_data[seq])\n",
        "\n",
        "        output_list = list(output_data[seq])\n",
        "        output_list = ['\\t'] + output_list + ['\\n']\n",
        "\n",
        "        input_seqs.append(input_list)\n",
        "        output_seqs.append(output_list)\n",
        "\n",
        "        for input_ch in input_list:\n",
        "            input_chars.add(input_ch)\n",
        "        \n",
        "        for output_ch in output_list:\n",
        "            output_chars.add(output_ch)\n",
        "                \n",
        "    \n",
        "    input_chars = sorted(list(input_chars))\n",
        "    output_chars = sorted(list(output_chars))\n",
        "    \n",
        "    max_len_input = max([len(seq) for seq in input_seqs])\n",
        "    max_len_output = max([len(seq) for seq in output_seqs])\n",
        "    \n",
        "    # shuffle the data. The model will get the data in small batches, it is preferable if the batches are more or less homogeneous\n",
        "    # of course the inputs and outputs have to be shuffled identically\n",
        "    input_seqs, output_seqs = shuffle(input_seqs, output_seqs)\n",
        "    \n",
        "    return input_seqs, output_seqs, input_chars, output_chars, max_len_input, max_len_output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtME9YqBpyqX"
      },
      "source": [
        "def create_dicts(input_voc, output_voc):\n",
        "    \n",
        "    # these dicts map the input sequences\n",
        "    input_idx2char = {}\n",
        "    input_char2idx = {}\n",
        "\n",
        "    for k, v in enumerate(input_voc):\n",
        "        input_idx2char[k] = v\n",
        "        input_char2idx[v] = k\n",
        "     \n",
        "    # and these dicts map the output sequences of parts of speech\n",
        "    output_idx2char = {}\n",
        "    output_char2idx = {}\n",
        "    \n",
        "    for k, v in enumerate(output_voc):\n",
        "        output_idx2char[k] = v\n",
        "        output_char2idx[v] = k\n",
        "        \n",
        "    return input_idx2char, input_char2idx, output_idx2char, output_char2idx"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tIxQP-fpyqZ"
      },
      "source": [
        "def one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_chars, input_char2idx, output_char2idx, input_seqs, output_seqs):\n",
        "    \n",
        "    # three-dimensional numpy arrays are created \n",
        "    tokenized_input = np.zeros(shape = (nb_samples, max_len_input, len(input_chars)), dtype='float32')\n",
        "    tokenized_output = np.zeros(shape = (nb_samples, max_len_output, len(output_chars)), dtype='float32')\n",
        "    target_data = np.zeros((nb_samples, max_len_output, len(output_chars)), dtype='float32')\n",
        "\n",
        "    for i in range(nb_samples):\n",
        "        for k, ch in enumerate(input_seqs[i]):\n",
        "            tokenized_input[i, k, input_char2idx[ch]] = 1\n",
        "        \n",
        "        for k, ch in enumerate(output_seqs[i]):\n",
        "            tokenized_output[i, k, output_char2idx[ch]] = 1\n",
        "\n",
        "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
        "            if k > 0:\n",
        "                target_data[i, k-1, output_char2idx[ch]] = 1\n",
        "                \n",
        "    return tokenized_input, tokenized_output, target_data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ozbSWfGpyqc"
      },
      "source": [
        "from tensorflow.keras.layers import Attention\n",
        "\n",
        "def define_LSTM_model(input_chars, output_chars):\n",
        "\n",
        "    # encoder model\n",
        "    encoder_input = Input(shape=(None,len(input_chars)))\n",
        "    encoder_LSTM = LSTM(500,activation='relu',return_state=True, return_sequences=True)(encoder_input)\n",
        "    encoder_LSTM = LSTM(500,return_state=True)(encoder_LSTM)\n",
        "    encoder_outputs, encoder_h, encoder_c = encoder_LSTM\n",
        "    encoder_states = [encoder_h, encoder_c]\n",
        "    \n",
        "\n",
        "    # decoder model\n",
        "    decoder_input = Input(shape=(None,len(output_chars)))\n",
        "    decoder_LSTM = LSTM(500, return_sequences=True, return_state = True)\n",
        "    decoder_out1, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(len(output_chars), activation='softmax')\n",
        "    decoder_out2 = decoder_dense(decoder_out1)\n",
        "\n",
        "    # Attention layer\n",
        "    attention_layer = Attention()([encoder_outputs, decoder_out1])\n",
        "  \n",
        "\n",
        "    model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out2])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return encoder_input, encoder_states, decoder_input, decoder_out2, decoder_dense, model"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOHzAZuhpyqe"
      },
      "source": [
        "def compile_and_train(model, one_hot_in, one_hot_out, targets, batch_size, epochs, val_split):\n",
        "\n",
        "    callback = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\n",
        "    adam = Adam(lr=0.0006, beta_1=0.995, beta_2=0.999, epsilon=0.00000001)\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy')\n",
        "    model.fit(x=[one_hot_in,one_hot_out], \n",
        "              y=targets,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_split=val_split,\n",
        "              callbacks=[callback])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5fB3BY6pyqf",
        "outputId": "38ec17d9-4692-4536-a7e7-f08db8c18ad0"
      },
      "source": [
        "input_seqs, output_seqs, input_chars, output_chars, max_len_input, max_len_output = prepare_train_data(all_in_seqs, all_out_seqs)\n",
        "print(len(input_seqs))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "299488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tiTdxB1ru4a"
      },
      "source": [
        "input_idx2char, input_char2idx, output_idx2char, output_char2idx = create_dicts(input_chars, output_chars)\n",
        "\n",
        "nb_samples = len(input_seqs)\n",
        "one_hot_input, one_hot_output, target_data = one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_chars, input_char2idx, output_char2idx, input_seqs, output_seqs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzQjon-TvaKu"
      },
      "source": [
        "train_size = 290000\n",
        "\n",
        "one_hot_input_train = one_hot_input[0:train_size]\n",
        "one_hot_output_train = one_hot_output[0:train_size]\n",
        "target_data_train = target_data[0:train_size]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IstZeGQXvKBX",
        "outputId": "f70efa69-9499-4a48-acae-9461d6de3aba"
      },
      "source": [
        "print(max_len_input, max_len_output)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2-mT3Plpyqk"
      },
      "source": [
        "encoder_input, encoder_states, decoder_input, decoder_out1, attention_layer, model = define_LSTM_model(input_chars, output_chars)\n",
        "model = compile_and_train(model, one_hot_input_train, one_hot_output_train, target_data_train, 1024, 150, 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}