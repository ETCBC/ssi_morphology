{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kopie van Kopie van morphological_analysis_workshop.ipynb","provenance":[{"file_id":"https://github.com/ETCBC/ssi_morphology/blob/master/Morphological_Analysis_Attention.ipynb","timestamp":1629481620137}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NaKh2cO7pyqL","executionInfo":{"status":"ok","timestamp":1629651892803,"user_tz":-120,"elapsed":3155,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["import os, collections\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.utils import shuffle\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6eMCeWlqZb1","executionInfo":{"status":"ok","timestamp":1629651923342,"user_tz":-120,"elapsed":25828,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"46d1e425-23a9-4949-ec3d-62ab36351a72"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/your_project_folder/' "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EyopyWzHMJRG","executionInfo":{"status":"ok","timestamp":1629651965630,"user_tz":-120,"elapsed":435,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def read_data_from_file(filename, data_dict):\n","\n","    with open(filename) as fp:\n","        line = fp.readline()\n","        while line:\n","            bo, ch, ve, text = tuple(line.strip().split('\\t'))\n","            words = text.split()\n","            for w in words:  \n","                # in the output data, composite placenames have a '_', which cannot be found in the input data\n","                words_split = w.split('_')               \n","                for word_split in words_split:\n","                    data_dict[bo].append(word_split)\n","        \n","            line = fp.readline()\n","            \n","    return data_dict"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PrQKfBKjMJRH","executionInfo":{"status":"ok","timestamp":1629651969909,"user_tz":-120,"elapsed":823,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["input_file = '/content/t-in_voc'\n","input_data = collections.defaultdict(list)\n","\n","output_file = '/content/t-out'\n","output_data = collections.defaultdict(list)\n","\n","input_data = read_data_from_file(input_file, input_data)\n","output_data = read_data_from_file(output_file, output_data)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MV9j5WDmePaw","executionInfo":{"status":"ok","timestamp":1629651973052,"user_tz":-120,"elapsed":366,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"dacaee0f-11c0-47eb-d6da-f2ce447e7a90"},"source":["print(len(input_data['Gen']))\n","print(len(output_data['Gen']))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["20611\n","20611\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gmq4ubmfMJRH","executionInfo":{"status":"ok","timestamp":1629651976050,"user_tz":-120,"elapsed":404,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"54a03c8a-aac8-4828-81b1-37ae654020f7"},"source":["input_data['Gen'][0:10]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B.:R;>CIJT',\n"," 'B.@R@>',\n"," '>:ELOHIJM',\n"," '>;T',\n"," 'HAC.@MAJIM',\n"," 'W:>;T',\n"," 'H@>@REY',\n"," 'W:H@>@REY',\n"," 'H@J:T@H',\n"," 'TOHW.']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNedXVOlMJRI","executionInfo":{"status":"ok","timestamp":1629651978918,"user_tz":-120,"elapsed":395,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"01458be2-82e9-48cc-aaa1-839a3feb6db3"},"source":["output_data['Gen'][0:10]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B-R>CJT/',\n"," 'BR>[',\n"," '>LH(J(M/JM',\n"," '>T',\n"," 'H-CMJ(M/(JM',\n"," 'W->T',\n"," 'H->RY/:a',\n"," 'W-H->RY/:a',\n"," 'HJ(H[&TH',\n"," 'THW/']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"-7c1KmcIMJRI","executionInfo":{"status":"ok","timestamp":1629651981580,"user_tz":-120,"elapsed":410,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def make_in_out_sequences(data_dict, sequence_length):\n","    \n","    all_sequences = []\n","    for words_list in data_dict.values():\n","\n","        for w in range(len(words_list) - sequence_length + 1):\n","    \n","            seq = ' '.join([words_list[ind] for ind in list(range(w, w + sequence_length))])\n","        \n","            # remove some special signs from output data (':', and '='). These only make the sequences longer.\n","            seq = seq.replace(\"=\", \"\").replace(\":a\", \"a\").replace(\":c\", \"c\").replace(\":d\", \"d\").replace(\":du\", \"du\")\n","            all_sequences.append(seq)\n","        \n","    return all_sequences"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2BUTP84XjF1","executionInfo":{"status":"ok","timestamp":1629652005117,"user_tz":-120,"elapsed":1320,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["sequence_length = 1\n","\n","all_in_seqs = make_in_out_sequences(input_data, sequence_length)\n","all_out_seqs = make_in_out_sequences(output_data, sequence_length)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38gyv323MJRJ","executionInfo":{"status":"ok","timestamp":1629652007329,"user_tz":-120,"elapsed":356,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"376f7395-82b6-49a2-d695-c1b49cd3e0d0"},"source":["all_in_seqs[0:10]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B.:R;>CIJT',\n"," 'B.@R@>',\n"," '>:ELOHIJM',\n"," '>;T',\n"," 'HAC.@MAJIM',\n"," 'W:>;T',\n"," 'H@>@REY',\n"," 'W:H@>@REY',\n"," 'H@J:T@H',\n"," 'TOHW.']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GI4oTf5eX2Sn","executionInfo":{"status":"ok","timestamp":1629652010047,"user_tz":-120,"elapsed":418,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"45acfc3d-82ef-4190-a010-386b8403ff44"},"source":["print(len(all_in_seqs))\n","print(len(all_out_seqs))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["300676\n","300676\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xv8HuH9lKJGl","executionInfo":{"status":"ok","timestamp":1629652012814,"user_tz":-120,"elapsed":394,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"1d733767-0889-4648-8cec-5fdb94998389"},"source":["for i in range(206000,206020):\n","  print(all_in_seqs[i], '---', all_out_seqs[i])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["B.:BOW>@M --- B-!!BW>[/+M\n","J@BOW> --- !J!BW>[\n","W.B:Y;>T@M --- W-B-!!(JY>[/T+M\n","J;Y;>W. --- !J!(JY>[W\n","W.BAXAG.IJM --- W-B-(H-XG/JM\n","W.BAM.OW<:ADIJM --- W-B-(H-MW<D/JM\n","T.IH:JEH --- !T!HJH[\n","HAM.IN:X@H --- H-MNX(H/H\n",">;JP@H --- >JP(H/H\n","LAP.@R --- L-(H-PR/a\n","W:>;JP@H --- W->JP(H/H\n","L@>AJIL --- L-(H->JL/a\n","W:LAK.:B@FIJM --- W-L-(H-KBF/JM\n","MAT.AT --- MTT/\n","J@DOW --- JD/+W\n","W:CEMEN --- W-CMN/\n","HIJN --- HJN/\n","L@>;JP@H --- L-(H->JP(H/H\n","W:KIJ --- W-KJ\n","JA<:AFEH --- !J!<FH[\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oXhrQPM4pyqV","executionInfo":{"status":"ok","timestamp":1629652016091,"user_tz":-120,"elapsed":400,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def prepare_train_data(input_data, output_data):\n","\n","    input_seqs = []\n","    output_seqs = []\n","    input_chars = set()\n","    output_chars = set()\n","\n","    # iterate over all the books\n","    for seq in range(len(input_data)): \n","      \n","        #if len(output_data[seq]) > 40:\n","        #  continue\n","          \n","        if \"*\" in input_data[seq]: # cases of ketiv/qere are complicated, just skip them!\n","          continue\n","\n","        input_list = list(input_data[seq])\n","\n","        output_list = list(output_data[seq])\n","        output_list = ['\\t'] + output_list + ['\\n']\n","\n","        input_seqs.append(input_list)\n","        output_seqs.append(output_list)\n","\n","        for input_ch in input_list:\n","            input_chars.add(input_ch)\n","        \n","        for output_ch in output_list:\n","            output_chars.add(output_ch)\n","                \n","    \n","    input_chars = sorted(list(input_chars))\n","    output_chars = sorted(list(output_chars))\n","    \n","    max_len_input = max([len(seq) for seq in input_seqs])\n","    max_len_output = max([len(seq) for seq in output_seqs])\n","    \n","    # shuffle the data. The model will get the data in small batches, it is preferable if the batches are more or less homogeneous\n","    # of course the inputs and outputs have to be shuffled identically\n","    input_seqs, output_seqs = shuffle(input_seqs, output_seqs)\n","    \n","    return input_seqs, output_seqs, input_chars, output_chars, max_len_input, max_len_output"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtME9YqBpyqX","executionInfo":{"status":"ok","timestamp":1629652020279,"user_tz":-120,"elapsed":322,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def create_dicts(input_voc, output_voc):\n","    \n","    # these dicts map the input sequences\n","    input_idx2char = {}\n","    input_char2idx = {}\n","\n","    for k, v in enumerate(input_voc):\n","        input_idx2char[k] = v\n","        input_char2idx[v] = k\n","     \n","    # and these dicts map the output sequences of parts of speech\n","    output_idx2char = {}\n","    output_char2idx = {}\n","    \n","    for k, v in enumerate(output_voc):\n","        output_idx2char[k] = v\n","        output_char2idx[v] = k\n","        \n","    return input_idx2char, input_char2idx, output_idx2char, output_char2idx"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tIxQP-fpyqZ","executionInfo":{"status":"ok","timestamp":1629652024073,"user_tz":-120,"elapsed":413,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_chars, input_char2idx, output_char2idx, input_seqs, output_seqs):\n","    \n","    # three-dimensional numpy arrays are created \n","    tokenized_input = np.zeros(shape = (nb_samples, max_len_input, len(input_chars)), dtype='float32')\n","    tokenized_output = np.zeros(shape = (nb_samples, max_len_output, len(output_chars)), dtype='float32')\n","    target_data = np.zeros((nb_samples, max_len_output, len(output_chars)), dtype='float32')\n","\n","    for i in range(nb_samples):\n","        for k, ch in enumerate(input_seqs[i]):\n","            tokenized_input[i, k, input_char2idx[ch]] = 1\n","        \n","        for k, ch in enumerate(output_seqs[i]):\n","            tokenized_output[i, k, output_char2idx[ch]] = 1\n","\n","            # decoder_target_data will be ahead by one timestep and will not include the start character.\n","            if k > 0:\n","                target_data[i, k-1, output_char2idx[ch]] = 1\n","                \n","    return tokenized_input, tokenized_output, target_data"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ozbSWfGpyqc","executionInfo":{"status":"ok","timestamp":1629652028066,"user_tz":-120,"elapsed":410,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["from tensorflow.keras.layers import Attention\n","\n","def define_LSTM_model(input_chars, output_chars):\n","\n","    # encoder model\n","    encoder_input = Input(shape=(None,len(input_chars)))\n","    encoder_LSTM = LSTM(500,activation='relu',return_state=True, return_sequences=True)(encoder_input)\n","    encoder_LSTM = LSTM(500,return_state=True)(encoder_LSTM)\n","    encoder_outputs, encoder_h, encoder_c = encoder_LSTM\n","    encoder_states = [encoder_h, encoder_c]\n","    \n","\n","    # decoder model\n","    decoder_input = Input(shape=(None,len(output_chars)))\n","    decoder_LSTM = LSTM(500, return_sequences=True, return_state = True)\n","    decoder_out1, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n","    decoder_dense = Dense(len(output_chars), activation='softmax')\n","    decoder_out2 = decoder_dense(decoder_out1)\n","\n","    # Attention layer\n","    attention_layer = Attention()([encoder_outputs, decoder_out1])\n","  \n","\n","    model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out2])\n","\n","    model.summary()\n","\n","    return encoder_input, encoder_states, decoder_input, decoder_out2, decoder_dense, model"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOHzAZuhpyqe","executionInfo":{"status":"ok","timestamp":1629652031958,"user_tz":-120,"elapsed":413,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def compile_and_train(model, one_hot_in, one_hot_out, targets, batch_size, epochs, val_split):\n","\n","    callback = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\n","    adam = Adam(lr=0.0006, beta_1=0.995, beta_2=0.999, epsilon=0.00000001)\n","    model.compile(optimizer=adam, loss='categorical_crossentropy')\n","    model.fit(x=[one_hot_in,one_hot_out], \n","              y=targets,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_split=val_split,\n","              callbacks=[callback])\n","    \n","    return model"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5fB3BY6pyqf","executionInfo":{"status":"ok","timestamp":1629652038100,"user_tz":-120,"elapsed":2586,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"df901665-463f-4096-d199-2ab13f1e7436"},"source":["input_seqs, output_seqs, input_chars, output_chars, max_len_input, max_len_output = prepare_train_data(all_in_seqs, all_out_seqs)\n","print(len(input_seqs))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["299488\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5tiTdxB1ru4a","executionInfo":{"status":"ok","timestamp":1629652045692,"user_tz":-120,"elapsed":4725,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["input_idx2char, input_char2idx, output_idx2char, output_char2idx = create_dicts(input_chars, output_chars)\n","\n","nb_samples = len(input_seqs)\n","one_hot_input, one_hot_output, target_data = one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_chars, input_char2idx, output_char2idx, input_seqs, output_seqs)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzQjon-TvaKu","executionInfo":{"status":"ok","timestamp":1629652048150,"user_tz":-120,"elapsed":316,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["train_size = 290000\n","\n","one_hot_input_train = one_hot_input[0:train_size]\n","one_hot_output_train = one_hot_output[0:train_size]\n","target_data_train = target_data[0:train_size]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IstZeGQXvKBX","executionInfo":{"status":"ok","timestamp":1629652050596,"user_tz":-120,"elapsed":412,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"a6bf79db-a8fd-4163-814e-8d9f72b02e8e"},"source":["print(max_len_input, max_len_output)\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["23 28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i2-mT3Plpyqk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629660599352,"user_tz":-120,"elapsed":8544331,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"3c6fc5e9-a674-4d5d-d75e-fdb2e4995762"},"source":["encoder_input, encoder_states, decoder_input, decoder_out1, attention_layer, model = define_LSTM_model(input_chars, output_chars)\n","model = compile_and_train(model, one_hot_input_train, one_hot_output_train, target_data_train, 1024, 150, 0.05)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 32)]   0                                            \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, None, 500),  1066000     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None, 42)]   0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 500), (None, 2002000     lstm[0][0]                       \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, None, 500),  1086000     input_2[0][0]                    \n","                                                                 lstm_1[0][1]                     \n","                                                                 lstm_1[0][2]                     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 42)     21042       lstm_2[0][0]                     \n","==================================================================================================\n","Total params: 4,175,042\n","Trainable params: 4,175,042\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/150\n","270/270 [==============================] - 135s 469ms/step - loss: 0.8380 - val_loss: 0.8146\n","Epoch 2/150\n","270/270 [==============================] - 125s 462ms/step - loss: 0.8191 - val_loss: 0.8004\n","Epoch 3/150\n","270/270 [==============================] - 125s 461ms/step - loss: 0.7911 - val_loss: 0.7785\n","Epoch 4/150\n","270/270 [==============================] - 125s 462ms/step - loss: 0.7734 - val_loss: 0.7597\n","Epoch 5/150\n","270/270 [==============================] - 125s 462ms/step - loss: 0.7469 - val_loss: 0.7351\n","Epoch 6/150\n","270/270 [==============================] - 124s 461ms/step - loss: 0.7225 - val_loss: 0.7096\n","Epoch 7/150\n","270/270 [==============================] - 125s 461ms/step - loss: 0.6972 - val_loss: 0.6813\n","Epoch 8/150\n","270/270 [==============================] - 124s 460ms/step - loss: 0.6714 - val_loss: 0.6665\n","Epoch 9/150\n","270/270 [==============================] - 125s 462ms/step - loss: 0.6604 - val_loss: 0.6461\n","Epoch 10/150\n","270/270 [==============================] - 125s 461ms/step - loss: 0.6275 - val_loss: 0.6188\n","Epoch 11/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.5998 - val_loss: 0.5959\n","Epoch 12/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.6123 - val_loss: 0.5866\n","Epoch 13/150\n","270/270 [==============================] - 125s 462ms/step - loss: 0.5768 - val_loss: 0.5582\n","Epoch 14/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.5438 - val_loss: 0.5264\n","Epoch 15/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.5296 - val_loss: 0.5222\n","Epoch 16/150\n","270/270 [==============================] - 125s 462ms/step - loss: 0.5077 - val_loss: 0.4912\n","Epoch 17/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.4839 - val_loss: 0.4981\n","Epoch 18/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.5062 - val_loss: 0.4986\n","Epoch 19/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.4699 - val_loss: 0.4506\n","Epoch 20/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.4527 - val_loss: 0.4433\n","Epoch 21/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.4385 - val_loss: 0.4331\n","Epoch 22/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.4229 - val_loss: 0.4220\n","Epoch 23/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.4071 - val_loss: 0.3953\n","Epoch 24/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3948 - val_loss: 0.3929\n","Epoch 25/150\n","270/270 [==============================] - 125s 463ms/step - loss: 0.3795 - val_loss: 0.3667\n","Epoch 26/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3719 - val_loss: 0.3643\n","Epoch 27/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3568 - val_loss: 0.3464\n","Epoch 28/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.3455 - val_loss: 0.3467\n","Epoch 29/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3364 - val_loss: 0.3270\n","Epoch 30/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3208 - val_loss: 0.3168\n","Epoch 31/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3100 - val_loss: 0.3014\n","Epoch 32/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3050 - val_loss: 0.3046\n","Epoch 33/150\n","270/270 [==============================] - 125s 464ms/step - loss: 0.3065 - val_loss: 0.3067\n","Epoch 34/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.2848 - val_loss: 0.2774\n","Epoch 35/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.2661 - val_loss: 0.2594\n","Epoch 36/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.2377 - val_loss: 0.2362\n","Epoch 37/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.2238 - val_loss: 0.2144\n","Epoch 38/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.2066 - val_loss: 0.2037\n","Epoch 39/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1950 - val_loss: 0.1960\n","Epoch 40/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.2019 - val_loss: 0.1938\n","Epoch 41/150\n","270/270 [==============================] - 125s 465ms/step - loss: 0.1783 - val_loss: 0.1783\n","Epoch 42/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1619 - val_loss: 0.1653\n","Epoch 43/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1528 - val_loss: 0.1535\n","Epoch 44/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.1427 - val_loss: 0.1450\n","Epoch 45/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1311 - val_loss: 0.1279\n","Epoch 46/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.1215 - val_loss: 0.1272\n","Epoch 47/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1204 - val_loss: 0.1148\n","Epoch 48/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1105 - val_loss: 0.1134\n","Epoch 49/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.1041 - val_loss: 0.1051\n","Epoch 50/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0972 - val_loss: 0.1020\n","Epoch 51/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0929 - val_loss: 0.0988\n","Epoch 52/150\n","270/270 [==============================] - 126s 467ms/step - loss: 0.0924 - val_loss: 0.0968\n","Epoch 53/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0897 - val_loss: 0.0897\n","Epoch 54/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.0840 - val_loss: 0.0876\n","Epoch 55/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0809 - val_loss: 0.0816\n","Epoch 56/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0745 - val_loss: 0.0732\n","Epoch 57/150\n","270/270 [==============================] - 125s 465ms/step - loss: 0.0651 - val_loss: 0.0697\n","Epoch 58/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0617 - val_loss: 0.0666\n","Epoch 59/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.0616 - val_loss: 0.0659\n","Epoch 60/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.0600 - val_loss: 0.0632\n","Epoch 61/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0593 - val_loss: 0.0672\n","Epoch 62/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.0594 - val_loss: 0.0634\n","Epoch 63/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0531 - val_loss: 0.0580\n","Epoch 64/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0490 - val_loss: 0.0550\n","Epoch 65/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.0471 - val_loss: 0.0520\n","Epoch 66/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0469 - val_loss: 0.0572\n","Epoch 67/150\n","270/270 [==============================] - 126s 465ms/step - loss: 0.0505 - val_loss: 0.0554\n","Epoch 68/150\n","270/270 [==============================] - 126s 466ms/step - loss: 0.0470 - val_loss: 0.0520\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bfQmBVQRn49U","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1629683082173,"user_tz":-120,"elapsed":923,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"49b49a76-72fc-44c9-fd0a-09b7e403db22"},"source":["# Encoder inference model\n","encoder_model_inf = Model(encoder_input, encoder_states)\n","\n","# Decoder inference model\n","decoder_input = Input(shape=(None,len(output_chars)))\n","decoder_LSTM = LSTM(500, return_sequences=True, return_state = True)\n","decoder_out1, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n","decoder_dense = Dense(len(output_chars), activation='softmax')\n","decoder_out2 = decoder_dense(decoder_out1)\n","decoder_state_input_h = Input(shape=(500,))\n","decoder_state_input_c = Input(shape=(500,))\n","decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n","decoder_LSTM = LSTM(500, return_sequences=True, return_state = True)\n","\n","decoder_out1, decoder_h, decoder_c = decoder_LSTM(decoder_input)\n","\n","decoder_states = [decoder_h , decoder_c]\n","\n","decoder_out = decoder_dense(decoder_out1)\n","\n","decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n","                          outputs=[decoder_out] + decoder_states )"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5ee9ce0fc53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encoder inference model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_model_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Decoder inference model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"rJCd_vz0oqvt","executionInfo":{"status":"ok","timestamp":1629660640070,"user_tz":-120,"elapsed":818,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}}},"source":["def decode_seq(inp_seq):\n","    \n","    states_val = encoder_model_inf.predict(inp_seq)\n","    \n","    target_seq = np.zeros((1, 1, len(output_chars)))\n","    target_seq[0, 0, output_char2idx['\\t']] = 1\n","    \n","    predicted_seq = []\n","    stop_condition = False\n","    \n","    while not stop_condition:\n","        \n","        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n","        \n","        max_val_index = np.argmax(decoder_out[0,-1,:])\n","        sampled_out_char = output_idx2char[max_val_index]\n","        predicted_seq.append(sampled_out_char)\n","        \n","        if (sampled_out_char == '\\n'):\n","            stop_condition = True\n","        \n","        target_seq = np.zeros((1, 1, len(output_chars)))\n","        target_seq[0, 0, max_val_index] = 1\n","        \n","        states_val = [decoder_h, decoder_c]\n","        \n","    return predicted_seq"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"a1Bt0Voso1JC","executionInfo":{"status":"error","timestamp":1629683062368,"user_tz":-120,"elapsed":10,"user":{"displayName":"Mathias Coeckelbergs","photoUrl":"","userId":"05079222742898328673"}},"outputId":"392d928f-92e4-416d-b5bd-1d7a0332dfd5"},"source":["all_preds = []\n","\n","in_ind = train_size + 1\n","out_ind = len(one_hot_input)\n","\n","#in_ind = 0\n","#out_ind = 1000\n","  \n","inputs = input_seqs[in_ind:out_ind]\n","one_hot_test_data = one_hot_input[in_ind:out_ind]\n","output_seqs_test = output_seqs[in_ind:out_ind]\n","\n","\n","for seq_index in range(len(one_hot_test_data)):\n","    inp_seq = one_hot_test_data[seq_index:seq_index+1]\n","    \n","    predicted_sequence = decode_seq(inp_seq)\n","    \n","    true_val = ''.join(output_seqs_test[seq_index][1:-1])\n","    pred_val = ''.join(predicted_sequence[0:-1])\n","    #print(''.join(inputs[seq_index]), true_val, pred_val)\n","    print(seq_index)\n","    all_preds.append((''.join(inputs[seq_index]), true_val, pred_val))"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-527256d672b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0min_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mout_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_size' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"id":"n4bbVz8so4jc","executionInfo":{"status":"error","timestamp":1629469200456,"user_tz":-120,"elapsed":236,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"b41e41ab-ba05-4d4b-c195-c3ca1e1469db"},"source":["corr = 0\n","\n","for item in all_preds:\n","  if item[1] == item[2]:\n","    corr += 1\n","    print(item[0], item[1], item[2], 'correct')\n","  else:\n","    print(item[0], item[1], item[2], 'wrong')\n"," \n","print(len(all_preds))\n","print(corr/len(all_preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"error","ename":"ZeroDivisionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-63c185a5941d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}]},{"cell_type":"code","metadata":{"id":"Iovyhv3eo_Uv"},"source":["len(all_preds)"],"execution_count":null,"outputs":[]}]}